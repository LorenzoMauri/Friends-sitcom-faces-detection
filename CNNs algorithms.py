# -*- coding: utf-8 -*-
"""DSIM riconoscimento immagini (CNN).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AmrUOWOrn7B0B0VgY_MGXmwBsIr4-pVV
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install git+https://github.com/rcmalli/keras-vggface.git
# Release Version
!pip install keras_vggface
!pip install keras_applications

"""# packages """

import tensorflow as tf
import tensorflow.keras.applications
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.applications import imagenet_utils
import numpy as np
from sklearn.model_selection import  GridSearchCV
from sklearn import metrics
import keras
from keras.models import Sequential
from keras.layers import Dense,Dropout
from keras.preprocessing.image import ImageDataGenerator
import os 
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
import seaborn as sns 
from sklearn.model_selection import train_test_split
import cv2
import random
from keras.utils.np_utils import to_categorical 
import pandas as pd 
import skimage.transform as st
import pickle
from keras.engine import  Model
from keras.layers import Flatten, Dense, Input
from skimage import io
from tensorflow.keras.preprocessing import image 
from keras_vggface.vggface import VGGFace
from skimage import transform
from sklearn.svm import SVC
import sklearn
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
from tensorflow.keras.applications.vgg16 import preprocess_input
import os
path = '/content/drive/MyDrive/script riconoscimento immagini /'
dataPath = path+'DATA/immagini CNN'
os.chdir(dataPath)
TEST_RATIO = 0.2
VALIDATION_RATIO=0.2
INPUT_SHAPE = (224,224)
IMAGE_DIMENSIONS = (224,224,3)
#--------------------------------------



############ UTILS ####################

def grayscale(img):
    img=np.float32(img)
    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    return img 

def preprocessing(img):
    img = grayscale(img)
    img=img/255
    return img

def loader(im_raw):
  return preprocessing(st.resize(im_raw,(1,4096)))

"""# Data Augmentation"""

os.chdir(path+'/'+'DATA/immagini CNN'+'/')
train_datagen = ImageDataGenerator(rescale = 1./255,
                                   zoom_range=[0.9,1.0] ,
                                   rotation_range = 40  ,
                                   width_shift_range=0.2,
                                  height_shift_range=0.2                
                                  
                                  )

training = train_datagen.flow_from_directory('training',
                                                 target_size = (224,224),
                                           
                                                 batch_size = 32,
                                                 class_mode = 'categorical',
                                                 shuffle = True
                                                  )


test_datagen = ImageDataGenerator(rescale = 1./255,
                                  zoom_range=[0.9,1.0]  ,
                                  rotation_range = 40 ,
                                  width_shift_range=0.2,
                                  height_shift_range=0.2                     
                                  
                                  )

test = test_datagen.flow_from_directory('test',
                                                 target_size = (224,224),
                                               
                                                 batch_size = 32,
                                                 class_mode = 'categorical',
                                                 shuffle = True
                                                  )

"""## Visualizzazioni"""

plt.rcParams['figure.figsize'] = [8,5]
plt.subplot(1,3,1); plt.imshow(training.next()[0][0]); 
plt.subplot(1,3,2); plt.imshow(training.next()[0][1]); 
plt.subplot(1,3,3); plt.imshow(training.next()[0][2]); 
plt.show()

plt.rcParams['figure.figsize'] = [8,5]
plt.subplot(1,3,1); plt.imshow(test.next()[0][0]); 
plt.subplot(1,3,2); plt.imshow(test.next()[0][1]); 
plt.subplot(1,3,3); plt.imshow(test.next()[0][2]); 
plt.show()

"""# VGGFACE fine tuning"""

#from tensorflow.keras.applications.vgg16 import VGG16

base_model = VGGFace(weights='vggface',include_top = False, input_shape = (224,224,3))

for layer in base_model.layers: 
  layer.trainable = False
  print('Layer ' + layer.name + ' frozen.')

last = base_model.layers[-1].output
x = Flatten()(last)
x = Dense(1000, activation='relu', name='fullyConnected_0')(x)
x = Dense(256, activation='relu', name='fullyConnected_1')(x)
x = Dropout(0.7)(x)
x = Dense(128, activation='relu', name='fullyConnected_2')(x)
x = Dense(7, activation='softmax', name='predictions')(x)
model = Model(base_model.input, x)

model.summary()

model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

modello = model.fit(x = training, validation_data = test, epochs = 20,batch_size = 128)

fig = plt.figure(figsize = [8,5])
plt.subplot(1, 2, 1)
plt.title('accuracy')
plt.plot(modello.history['accuracy'],label='training')
plt.plot(modello.history['val_accuracy'],label='validation')
plt.legend()

plt.subplot(1, 2, 2)
plt.title('loss')
plt.plot(modello.history['loss'],label='training')
plt.plot(modello.history['val_loss'],label='validation')
plt.legend()
  
plt.show()

"""# Demo predictions"""

os.chdir(path+'/'+'DATA/immagini CNN'+'/demo/')

im = plt.imread('PROVA.PNG');plt.imshow(im)

def getClassName(classNo):
    if classNo == 0 :
        return 'Chandler'
    elif classNo == 1 :
        return 'Janice'
    elif classNo == 2 :
        return 'Joey'
    elif classNo == 3 :
        return 'Monica'
    elif classNo == 4 :
        return 'Phoebe'
    elif classNo == 5 :
        return 'Rachel'
    else :  return 'Ross'
    
    
def predict_new(im):
  im2 = skimage.transform.resize(im,(1,224,224,3))  
  return getClassName(np.argmax(model.predict(im2)))

predict_new(im)

"""


---



# VGG16 CNN feature extractor



---





"""

from tensorflow.keras.applications.vgg16 import VGG16

base_model_fe = VGG16(weights = 'imagenet')
model_fe = Model(inputs=base_model_fe.input, outputs=base_model_fe.get_layer('block2_pool').output)
model_fe.summary()

last = model_fe.layers[-1].output
x = Flatten()(last)
x = Dense(1000, activation='relu', name='fullyConnected_0')(x)
x = Dense(1000, activation='relu', name='fullyConnected_1')(x)
x = Dense(128, activation='relu', name='fullyConnected_2')(x)
#x = Dense(256, activation='relu', name='fullyConnected_1')(x)
#x = Dropout(0.7)(x)
#x = Dense(128, activation='relu', name='fullyConnected_2')(x)

model_fe = Model(model_fe.input, x)

model_fe.summary()

features = model_fe.predict(training)

df=pd.DataFrame(features)
df.head()

df['labels']=training.labels
df.head()













"""

---



# SVC CLASSIFICATOR


---


"""

df.groupby(by='labels').size().plot.bar()

x_train,x_test,y_train,y_test= train_test_split(df.iloc[:,:-1],df.iloc[:,-1],test_size= 0.3,random_state=1234)

param_grid = {'C': [1,10,100,1000,10000,100000], 
              'gamma': [0.005, 0.01, 0.1,0.5,0.8,1],}

clf = GridSearchCV(SVC(kernel='linear',degree=3), param_grid, cv=2)

clf = clf.fit(x_train,y_train)

print(classification_report(y_test,clf.predict(x_test)))

print(classification_report(y_test,clf.predict(x_test)))

fig, ax = plt.subplots(figsize=(7,5)) 
confusion_matrix = sklearn.metrics.confusion_matrix(y_test,clf.predict(x_test))
sns.color_palette("flare", as_cmap=True)
sns.heatmap(confusion_matrix,annot=True,fmt='d',ax=ax)

k='/content/drive/MyDrive/script riconoscimento immagini /DATA/immagini CNN/4'
# simple version for working with CWD
len([name for name in os.listdir(k) ])

p='/content/drive/MyDrive/script riconoscimento immagini /DATA/immagini CNN/'

im = io.imread(p+'0/Chandler.03.png')
im_gray = preprocessing(im)
io.imshow(im_gray)

im_vector=st.resize(im_gray,(1,4096))
im_vector

clf.predict(im_vector)











